import numpy as np
from gensim.models import word2vec
from networkx import from_numpy_matrix
from BaseAlgorithm import BaseAlgorithm


class Node2Vec(BaseAlgorithm):
    """
    Main class for Node2Vec algorithm model.
    """

    def __init__(self, adjacency_matrix, le, r, p, q, dimension):
        """
        Node2Vec constructor.
        @param adjacency_matrix: Adjacency matrix representing graph.
        @param le: The length of a single random walk.
        @param r: Number of random walks starting at a single vertex.
        @param p: Bias parameter of the random walks (Return).
        @param q: Bias parameter of the random walks (In-Out).
        """
        if dimension <= 0:
            raise Exception("Embedding dimension must be bigger than 0.")
        self.S = self.load_adjacency_matrix(adjacency_matrix)
        self.L = le
        self.R = r
        self.P = p
        self.Q = q
        self.d = dimension
        self.G = from_numpy_matrix(np.array(self.S))
        self.__model = None
        super().__init__()

    def create_embedding(self, negative: int, alpha: float, min_alpha: float, hs: int, window: int, num_iter: int):
        """
        Simulate Node2Vec algorithm.
        @param negative: Number of samples for the Negative Sampling method.
        @param alpha: The starting learning rate of the model.
        @param min_alpha: The minimal learning rate of the model.
        @param hs: 0 or 1 - decide whether Hierarchical Softmax is used.
        @param window: The window size of the network.
        @param num_iter: Number of iterations of the training.
        :return embedding: Model of an embedding generated by Node2Vec.
        """
        nodes_proc, edges_proc = self.preprocess_modified_weights()
        walks = []
        nodes = list(self.G.nodes())
        for i in range(0, self.R):
            for node in nodes:
                walks.append(self.node_2_vec_walk(self.L, node, nodes_proc, edges_proc))

        string_walks = []
        for i in walks:
            current = []
            for j in i:
                current.append(str(j))
            string_walks.append(current)

        model = word2vec.Word2Vec(sentences=None,
                                  size=self.d,
                                  min_count=1,
                                  negative=negative,
                                  alpha=alpha,
                                  min_alpha=min_alpha,
                                  sg=1,
                                  hs=hs,
                                  window=window,
                                  sample=0,
                                  sorted_vocab=0)
        self.__model = model
        self.__model.build_vocab(sentences=string_walks)
        self.__model.train(string_walks,
                           epochs=num_iter,
                           total_examples=len(string_walks))
        ret_matrix = np.empty((len(self.S), self.d), dtype="float32")
        for i in np.arange(len(self.S)):
            ret_matrix[i, :] = self.__model.wv[str(i)]
        return ret_matrix

    def node_2_vec_walk(self, u, le, nodes, edges):
        """
        Create random node2vec walk.
        @param u: Starting node.
        @param le: Length of random walk.
        @param nodes: Preprocessed nodes using alias.
        @param edges: Preprocessed edges using alias.
        :return walk: Random walk generated by Node2vec algorithm.
        """
        walk = [u]
        curr = walk[-1]
        v_curr = sorted(self.G.neighbors(curr))
        draw = int(np.floor(np.random.rand() * len(nodes[curr][0])))
        if np.random.rand() < nodes[curr][1][draw]:
            walk.append(v_curr[draw])
        else:
            walk.append(v_curr[nodes[curr][0][draw]])
        for i in range(0, le - 1):
            curr = walk[-1]
            v_curr = sorted(self.G.neighbors(curr))
            if len(v_curr) <= 0:
                raise Exception("Graph cannot have single nodes.")
            else:
                prev = walk[-2]
                draw = int(np.floor(np.random.rand() * len(edges[(prev, curr)][0])))
                if np.random.rand() < edges[(prev, curr)][1][draw]:
                    walk.append(v_curr[draw])
                else:
                    walk.append(v_curr[edges[(prev, curr)][0][draw]])
        return walk

    def preprocess_modified_weights(self):
        """
        Preprocessing of transition probabilities for guiding the random walks.
        :return nodes, edges: Alias nodes and edges.
        """
        nodes = {}
        for node in self.G.nodes():
            probabilities = [1 for _ in sorted(self.G.neighbors(node))]
            normalized_probabilities = [float(probability) / sum(probabilities) for probability in probabilities]
            nodes[node] = self.create_utility_lists(normalized_probabilities)

        edges = {}
        for edge in self.G.edges():
            edges[edge] = self.get_alias_edge(edge[0], edge[1])
            edges[(edge[1], edge[0])] = self.get_alias_edge(edge[1], edge[0])

        return nodes, edges

    def get_alias_edge(self, source, other):
        """
        Get alias edge based on normalized probabilities.
        @param source: Source node.
        @param other: Node on the other end of the edge.
        :return list: Utility list from normalized probabilities
        """

        probabilities = []
        for neighbor in sorted(self.G.neighbors(other)):
            if neighbor == source:
                probabilities.append(1 / self.P)
            elif not self.G.has_edge(neighbor, source):
                probabilities.append(1 / self.Q)
            else:
                probabilities.append(1)
        normalized_probabilities = [float(probability) / sum(probabilities) for probability in probabilities]

        return self.create_utility_lists(normalized_probabilities)

    @staticmethod
    def create_utility_lists(probabilities):
        """
        Compute utility lists for non-uniform sampling from discrete distributions using Alias Sampling method.
        @param probabilities: List of normalized probabilities.
        :return p,list1: Lists of samplings.
        """
        list1 = np.zeros(len(probabilities))
        list2 = np.zeros(len(probabilities), dtype=np.int)
        smaller = []
        larger = []
        for i in range(0, len(probabilities)):
            list1[i] = len(probabilities) * probabilities[i]
            if list1[i] < 1.0:
                smaller.append(i)
            else:
                larger.append(i)

        while len(smaller) > 0 and len(larger) > 0:
            s = smaller.pop()
            la = larger.pop()

            list2[s] = la
            list1[la] = list1[la] + list1[s] - 1.0
            if list1[la] < 1.0:
                smaller.append(la)
            else:
                larger.append(la)

        return list2, list1
